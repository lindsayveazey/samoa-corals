{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will...\n",
    "   - calculate baseline error\n",
    "   - run random forest regressors on abundance \n",
    "   - load regional dfs, impute, add island col as ID, rbind all 5 dfs \n",
    "   - predict out for each group \n",
    "\n",
    "#### Scoring models\n",
    "\n",
    "We evaluated the performance of the abundance models based on mean average error (accuracy) and mean absolute percent error (MAPE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, confusion_matrix, auc\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import *\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "import requests\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/linds/OneDrive/Documents/samoa_corals_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "coral_types=['scler','branching','columnar','encrusting','free_livin','massive','plate']\n",
    "target_types=['binary','percent']\n",
    "df = dict()\n",
    "\n",
    "for i in range(0,len(coral_types)):\n",
    "    for j in range(0,len(target_types)):\n",
    "        df[str(coral_types[i])+'_'+str(target_types[j])]=pd.read_csv(str(coral_types[i])+'_'+str(target_types[j])+'.csv')\n",
    "        del df[str(coral_types[i])+'_'+str(target_types[j])]['Unnamed: 0'] # artifact indexing column\n",
    "# Access the data as, e.g., df['scler_percent']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scler (all corals)\n",
    "\n",
    "### Train/test split, baseline error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline is the estimate I would get if I simply predicted the average abundance across all cells. If I can improve upon this by using my model, then my approach is valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scler Training Features Shape: (1372, 9)\n",
      "Scler Training Labels Shape: (1372,)\n",
      "Scler Testing Features Shape: (588, 9)\n",
      "Scler Testing Labels Shape: (588,)\n",
      "Baseline prediction error:  14.31\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['scler_percent'].drop(['Sclr_Rw','lat','lon','ID'], axis=1), \n",
    "                                                    df['scler_percent']['Sclr_Rw'], \n",
    "                                                    test_size = 0.3, random_state = 30)\n",
    "\n",
    "\n",
    "print('Scler Training Features Shape:', X_train.shape)\n",
    "print('Scler Training Labels Shape:', y_train.shape)\n",
    "print('Scler Testing Features Shape:', X_test.shape)\n",
    "print('Scler Testing Labels Shape:', y_test.shape)\n",
    "\n",
    "# The baseline predictions are the averages\n",
    "\n",
    "baseline_preds = np.array([y_train.mean()] * len(y_train))\n",
    "baseline_errors = abs(baseline_preds - y_train)\n",
    "print('Baseline prediction error: ', round(np.mean(baseline_errors), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train random forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error:  10.22\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 30)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predicting to the test data\n",
    "predictions = rf.predict(X_test)\n",
    "\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - y_test)\n",
    "\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error: ', round(np.mean(errors), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the random forest regressor reduced predictive error by nearly 30% compared to the application of a \"baseline average\" for prediction (i.e., the calculation of a uniform basic average abundance of coral across the sample sites)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('scler_abundance_model.pkl', 'wb') as fid:\n",
    "    pickle.dump(rf, fid, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Branching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scler Training Features Shape: (2214, 9)\n",
      "Scler Training Labels Shape: (2214,)\n",
      "Scler Testing Features Shape: (949, 9)\n",
      "Scler Testing Labels Shape: (949,)\n",
      "Baseline prediction error:  2.54\n",
      "Mean Absolute Error:  2.18\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['branching_percent'].drop(['Brnch_R','lat','lon','ID'], axis=1), \n",
    "                                                    df['branching_percent']['Brnch_R'], \n",
    "                                                    test_size = 0.3, random_state = 99)\n",
    "\n",
    "\n",
    "print('Scler Training Features Shape:', X_train.shape)\n",
    "print('Scler Training Labels Shape:', y_train.shape)\n",
    "print('Scler Testing Features Shape:', X_test.shape)\n",
    "print('Scler Testing Labels Shape:', y_test.shape)\n",
    "\n",
    "baseline_preds = np.array([y_train.mean()] * len(y_train))\n",
    "baseline_errors = abs(baseline_preds - y_train)\n",
    "print('Baseline prediction error: ', round(np.mean(baseline_errors), 2))\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 99)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "predictions = rf.predict(X_test)\n",
    "errors = abs(predictions - y_test)\n",
    "\n",
    "print('Mean Absolute Error: ', round(np.mean(errors), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Columnar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scler Training Features Shape: (2214, 9)\n",
      "Scler Training Labels Shape: (2214,)\n",
      "Scler Testing Features Shape: (949, 9)\n",
      "Scler Testing Labels Shape: (949,)\n",
      "Baseline prediction error:  0.2\n",
      "Mean Absolute Error:  0.1\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['columnar_percent'].drop(['Clmnr_R','lat','lon','ID'], axis=1), \n",
    "                                                    df['columnar_percent']['Clmnr_R'], \n",
    "                                                    test_size = 0.3, random_state = 120)\n",
    "\n",
    "\n",
    "print('Scler Training Features Shape:', X_train.shape)\n",
    "print('Scler Training Labels Shape:', y_train.shape)\n",
    "print('Scler Testing Features Shape:', X_test.shape)\n",
    "print('Scler Testing Labels Shape:', y_test.shape)\n",
    "\n",
    "baseline_preds = np.array([y_train.mean()] * len(y_train))\n",
    "baseline_errors = abs(baseline_preds - y_train)\n",
    "print('Baseline prediction error: ', round(np.mean(baseline_errors), 2))\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 99)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "predictions = rf.predict(X_test)\n",
    "errors = abs(predictions - y_test)\n",
    "\n",
    "print('Mean Absolute Error: ', round(np.mean(errors), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encrusting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
