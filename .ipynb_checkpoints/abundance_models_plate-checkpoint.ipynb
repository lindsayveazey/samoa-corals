{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will...\n",
    "   - calculate baseline error\n",
    "   - run random forest regressors on abundance \n",
    "   - load regional dfs, impute, add island col as ID, rbind all 5 dfs \n",
    "   - predict out for each group \n",
    "\n",
    "#### Scoring models\n",
    "\n",
    "We evaluated the performance of the abundance models based on mean average error (accuracy) and mean absolute percent error (MAPE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, confusion_matrix, auc\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import *\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "import requests\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/linds/OneDrive/Documents/samoa_corals_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "coral_types=['plate']\n",
    "target_types=['binary','percent']\n",
    "df = dict()\n",
    "\n",
    "for i in range(0,len(coral_types)):\n",
    "    for j in range(0,len(target_types)):\n",
    "        df[str(coral_types[i])+'_'+str(target_types[j])]=pd.read_csv(str(coral_types[i])+'_'+str(target_types[j])+'.csv')\n",
    "        del df[str(coral_types[i])+'_'+str(target_types[j])]['Unnamed: 0'] # artifact indexing column\n",
    "# Access the data as, e.g., df['scler_percent']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scler (all corals)\n",
    "\n",
    "### Train/test split, baseline error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline is the estimate I would get if I simply predicted the average abundance across all cells. If I can improve upon this by using my model, then my approach is valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plate Training Features Shape: (1372, 10)\n",
      "Plate Training Labels Shape: (1372,)\n",
      "Plate Testing Features Shape: (588, 10)\n",
      "Plate Testing Labels Shape: (588,)\n",
      "Baseline prediction error:  9.3\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['plate_percent'].drop(['Plt_L_R','lat','lon','ID'], axis=1), \n",
    "                                                    df['plate_percent']['Plt_L_R'], \n",
    "                                                    test_size = 0.3, random_state = 30)\n",
    "\n",
    "\n",
    "print('Plate Training Features Shape:', X_train.shape)\n",
    "print('Plate Training Labels Shape:', y_train.shape)\n",
    "print('Plate Testing Features Shape:', X_test.shape)\n",
    "print('Plate Testing Labels Shape:', y_test.shape)\n",
    "\n",
    "# The baseline predictions are the averages\n",
    "\n",
    "baseline_preds = np.array([y_train.mean()] * len(y_train))\n",
    "baseline_errors = abs(baseline_preds - y_train)\n",
    "print('Baseline prediction error: ', round(np.mean(baseline_errors), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train random forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error:  9.03\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 30)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predicting to the test data\n",
    "predictions = rf.predict(X_test)\n",
    "\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - y_test)\n",
    "\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error: ', round(np.mean(errors), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'bootstrap': [True, False]}\n",
      "Fitting 10 folds for each of 40 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  5.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1000, 'max_features': 'sqrt', 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "bootstrap = [True, False] # Create the random grid\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "print(random_grid)\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Random search of parameters, using 10 fold cross validation, \n",
    "# Search across n_iter * cv different combinations, and use all available cores\n",
    "rf_best = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 40, cv = 10, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_best.fit(X_train, y_train)\n",
    "print(rf_best.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error:  8.77\n"
     ]
    }
   ],
   "source": [
    "#Predicting on the test set\n",
    "predictions = rf_best.predict(X_test)\n",
    "\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - y_test)\n",
    "\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error: ', round(np.mean(errors), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error:  8.79\n",
      "[('bty', 0.15), ('rug', 0.13), ('slope', 0.12), ('vill_ed', 0.12), ('asp', 0.11), ('shore_ed', 0.11), ('esi_ed', 0.11), ('hs', 0.07), ('ucur', 0.04), ('vcur', 0.04)]\n"
     ]
    }
   ],
   "source": [
    "# Retrain with the optimal parameters\n",
    "rf = RandomForestRegressor(n_estimators = 1000, max_features = 'sqrt', bootstrap = True, random_state = 30)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predicting to the test data\n",
    "predictions = rf.predict(X_test)\n",
    "\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - y_test)\n",
    "\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error: ', round(np.mean(errors), 2))\n",
    "\n",
    "# Get numerical feature importances\n",
    "feature_list = list(X_train.columns)\n",
    "importances = list(rf.feature_importances_)\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "print(feature_importances)\n",
    "\n",
    "# Save the test data (actual) and predictions to df for visualizations later\n",
    "plate_preds = pd.DataFrame(data = {'actual': y_test, 'prediction': predictions})\n",
    "plate_preds.to_csv('plate_preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('plate_abundance_model.pkl', 'wb') as fid:\n",
    "#    pickle.dump(rf, fid, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.976822157434403\n",
      "11.176227688116423\n"
     ]
    }
   ],
   "source": [
    "AS_all = pd.read_csv('AS_all.csv')\n",
    "\n",
    "# plate: bty, hs, rug, slope, asp, shore_ed, vill_ed, esi_ed, ucur, vcur\n",
    "plate_pred_out = AS_all[['bty', 'hs', 'rug', 'slope', 'asp', 'shore_ed', 'vill_ed', 'esi_ed', 'ucur', 'vcur']]\n",
    "plate_predictions = rf_best.predict(plate_pred_out)\n",
    "\n",
    "print(y_train.mean())\n",
    "print(plate_predictions.mean())\n",
    "AS_all['plate_preds'] = plate_predictions\n",
    "AS_all.to_csv('AS_all.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
